---
title: "Simple Linear Model"
author: "Boyko Amarov"
date: "3/28/2022"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
invoices <- read.delim('https://raw.githubusercontent.com/feb-uni-sofia/econometrics2020-solutions/master/data/invoices.txt')
```


```{r}
glimpse(invoices)
```

Variablenbeschreibung:

- `Day` (numeric): Tag
- `Invoices` (numeric): Anzahl von Rechnungen
- `Time` (numeric): Bearbeitungszeit (Stunden)

Unsere Aufgabe ist, die Bearbeitungszeit für 50, 120, 201, 250 und 400 Rechnungen zu schätzen.

```{r}
ggplot(data = invoices, aes(x = Invoices, y = Time)) + 
  geom_point() +
  geom_vline(xintercept = c(50, 120, 201, 250, 400), lty = 2, alpha = 0.5) +
  scale_x_continuous(breaks = c(50, 120, 201, 250, 400)) +
  geom_abline(slope = 0.015, intercept = 0.1) +
  ylim(c(0, 7)) +
  geom_abline(slope = 0.001, intercept = 0.1, color = "firebrick")

# +
  # geom_vline(xintercept = 120, lty = 2) +
  # geom_hline(yintercept = 2.110) +
  # geom_abline(intercept = 0.1, slope = 0.015, colour = "steelblue2")
```

<!-- Estimate the expected processing time for 50, 120, 201, 250, 400 invoices (3 estimates). -->

<!-- Strategy 1: Use the average processing time for the predictions -->

$$
i = 1,\ldots,n = 30\\
x_i: \text{ Anzahl von Rechnungen an Tag } i \\
y_i: \text{ Bearbeitungszeit an Tag } i \\
$$
Angenommen, die Beziehung zwischen $y_i$ und $x_i$ die folgende Regel befolgt.

$$
y_i = 0.1 + 0.015x_i
$$
Diese Gleichung ist zu restriktiv, um die beobachteten Bearbeitungszeiten zu beschreiben. Wir erweitern sie um einen Zufallsterm (Störterme) $u_i$.

$$
y_i = 0.1 + 0.015x_i + u_i
$$

1) Wir nehmen an, daß die Terme $u_i$ normalverteilt mit Erwartungswert 0 und Varianz $\sigma^2$ sind.

$$
u_i \sim N(0, \sigma^2)
$$

2) Die Terme $u_i$ sind voneinander unabhängig.

$$
E(y_i) = E(0.1 + 0.015x_i + u_i)\\
E(y_i) = E(0.1) + E(0.015x_i) + E(u_i) \\
E(y_i) = 0.1 + 0.015x_i + 0 \\
E(y_i) = 0.1 + 0.015x_i
$$
The _expected_ processing time $E(y_i|x_i)$ is equal to $0.1 + 0.015x_i$.

$$
y_i = \underbrace{0.1 + 0.015x_i}_{\text{Systematic part}} + \underbrace{u_i}_{\text{Random part}}
$$

## Simulation

Normal distribution

```{r}
# r: random (zufällig), norm: normal (Normalverteilung)
# mean: Erwartungswert der Verteilung, 
# sd: Standardabweichung der Verteilung = Quadratische Wurzel aus der Varianz

u <- rnorm(1000, mean = 0, sd = 1)
# u
```




```{r}
tibble(u) %>%
  ggplot(aes(x = u)) +
    geom_histogram(bins = 30)
```


```{r}
n <- 30
x <- round(seq(10, 250, length.out = n), 0)
## Select values at random from a standard 
## normal distribution, i.e. mean = 0, standard dev. = 0.5
u <- rnorm(n, mean = 0, sd = 0.5)
y <- 0.1 + 0.015 * x + u

tibble(x = x, y = y) %>%
  ggplot(aes(x = x, y = y)) + 
    geom_point() +
    geom_abline(intercept = 0.1, slope = 0.015) +
    xlim(c(0, 250))
```


```{r}
tibble(x, y)
```
Meßeinheiten.

$$
x_i: \text{ Anzahl von Rechnungen an Tag } i \\
y_i: \text{ Bearbeitungszeit an Tag } i \text{ (Stunden)} \\
y_i [Stunden] = 0.1[Stunden] + 0.015 [\frac{Stunden}{Rechnung}] x_i [\#Rechnungen] + u_i [Stunden]
$$
## Methode der kleinsten Quadrate

$$
y_i = 0.1 + 0.015x_i + u_i
$$

$$
y_i = \beta_0 + \beta_1 x_i + u_i, \quad \beta_0, \beta_1 \in \mathbf{R}
$$

Geschätzte Regressionsgerade

$$
\hat{y}_i = \hat{\beta}_0 + \hat{\beta_1} x_i
$$
Residuum
$$
r_i = y_i - \hat{y}_i
$$
z.B mit den Koeffizienten 0.1; 0.015 ist das Residuum der 1. Beobachtung:

$$
i = 1, x_1 = 149, y_1 = 2.1\\
\hat{y}_1 = 0.1 + 0.015 \cdot 149 = 2.335 [Stunden]\\
r_1 = 2.1 - 2.335 = -0.235
$$
Berechnung der Residuen für alle Beobachtungen im Datensatz:

```{r}
invoices <- invoices %>%
  mutate(
    y_hat_manuell = 0.1 + 0.015 * Invoices,
    residuen_manuell = Time  - y_hat_manuell
  )
```


$$
\frac{1}{n}\sum_{i = 1}^{n}r_i = \frac{1}{n}\sum_{i = 1}^{n}(y_i - \hat{y}_i) = \frac{1}{n}\sum_{i = 1}^{n}(y_i - \hat{\beta}_0 - \hat{\beta_1} x_i)
$$

$$
\frac{1}{n}\sum_{i = 1}^{n}(y_i - \hat{y}_i) = \frac{1}{n}\sum_{i = 1}^{n}y_i - \frac{1}{n}\sum_{i = 1}^{n}\hat{y}_i
$$

$$
\min_{\hat{\beta}_0, \hat{\beta}_1} = RSS(\hat{\beta}_0, \hat{\beta}_1) = \sum_{i = 1}^{n}r_i^2 = \sum_{i = 1}^{n}(y_i - \hat{y}_i)^2
$$

Residual Sum of Squares: Residuen QuadratSumme. Die Lösung für die Betas heißt die KleinstQuadrateSchätzung (KQ-Schätzung, OLS: ordinary least squares).

$$
y_i = \beta_0 + \beta_1 x_i + u_i, \quad \beta_0, \beta_1 \in \mathbf{R}
$$

```{r}
## lm: Linear Model
lm(Time ~ 1 + Invoices, data = invoices)
```

$$
\hat{\beta}_0 = 0.64171, \hat{\beta}_1 = 0.01129\\
\hat{y}_i = 0.64171 + 0.01129 x_i
$$

```{r}
ggplot(data = invoices, aes(x = Invoices, y = Time)) + 
  geom_point() +
  geom_vline(xintercept = c(50, 120, 201, 250, 400), lty = 2, alpha = 0.5) +
  scale_x_continuous(breaks = c(50, 120, 201, 250, 400)) +
  geom_abline(slope = 0.015, intercept = 0.1) +
  ylim(c(0, 7)) +
  geom_abline(slope = 0.001, intercept = 0.1, color = "firebrick") +
  geom_abline(slope = 0.01129, intercept = 0.64171, color = "steelblue")
```

```{r}
invoices %>%
  mutate(
    y_hat_manuell = 0.23 - 0.015 * Invoices,
    residuen_manuell = Time  - y_hat_manuell,
    y_hat_KQ = 0.64171 + 0.01129 * Invoices,
    residuen_KQ = Time - y_hat_KQ
  ) %>%
  summarise(
    RSS_manuell = sum(residuen_manuell ^ 2),
    RSS_KQ = sum(residuen_KQ ^ 2)
  )
```


